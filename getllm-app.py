import streamlit as st
import requests
from bs4 import BeautifulSoup
import datetime
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

# è®¾ç½®é¡µé¢æ ‡é¢˜
st.set_page_config(page_title='å¤šé¡µé¢åº”ç”¨')

# åˆ›å»ºç¬¬ä¸€ä¸ªé¡µé¢
def search_github():
    st.title('GitHub é¡¹ç›®æœç´¢')

    # è¾“å…¥å…³é”®è¯
    keyword = st.text_input("è¾“å…¥å…³é”®è¯")
    count = st.number_input("è¾“å…¥æ•°é‡", min_value=1, step=1)

    # å½“ç”¨æˆ·ç‚¹å‡»â€œæœç´¢â€æŒ‰é’®æ—¶æ‰§è¡Œçš„å‡½æ•°
    if st.button('æœç´¢'):
        # ä½¿ç”¨GitHub APIè¿›è¡Œæœç´¢
        url = f"https://api.github.com/search/repositories?q={keyword}&sort=stars&order=desc"
        response = requests.get(url).json()
        projects = response['items'][:count]

        for project in projects:
            st.subheader(project['name'])
            st.write(f"Star Count: {project['stargazers_count']}")
            st.write(f"Project Link: [{project['html_url']}]({project['html_url']})")
            st.write(f"Description: {project['description']}")
            st.write('---')


# åˆ›å»ºç¬¬äºŒä¸ªé¡µé¢
def search_arxiv():
    st.title('Arxiv æœ€æ–°è®ºæ–‡')

    def translate_english_to_chinese(text):
        model_name = "Helsinki-NLP/opus-mt-en-zh"  # è‹±æ–‡åˆ°ä¸­æ–‡çš„ç¿»è¯‘æ¨¡å‹
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

        max_length = 4000  # æ¯ä¸ªæ‹†åˆ†çš„æœ€å¤§é•¿åº¦ï¼Œæ ¹æ®æ¨¡å‹çš„æœ€å¤§è¾“å…¥é•¿åº¦è¿›è¡Œè°ƒæ•´
        split_texts = [text[i:i+max_length] for i in range(0, len(text), max_length)]

        translated_texts = []
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model.to(device)

        for split_text in split_texts:
            inputs = tokenizer.encode(split_text, return_tensors="pt", padding=True, truncation=True).to(device)
            outputs = model.generate(inputs)
            translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)
            translated_texts.append(translated_text)

        return ''.join(translated_texts)


    # è¾“å…¥å…³é”®è¯
    keywords = st.text_input('è¾“å…¥å…³é”®è¯ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰')
    quantity = st.number_input('è¯·è¾“å…¥è¦æœç´¢çš„é¡¹ç›®æ•°é‡', min_value=1, step=1)


    if st.button('æœç´¢'):
        st.write('æ­£åœ¨æœç´¢ Arxiv...')
        keyword_list = keywords.split(',')

        for keyword in keyword_list:
            st.subheader(f'å…³é”®è¯: {keyword}')
            today = datetime.date.today()
            url = f"https://arxiv.org/search/?query={keyword}&searchtype=all&abstracts=show&order=-announced_date_first&size=50"
            response = requests.get(url)
            soup = BeautifulSoup(response.content, 'html.parser')
            paper_list = soup.find_all('li', class_='arxiv-result')

            if len(paper_list) == 0:
                st.write('æ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„è®ºæ–‡ã€‚')
            else:
                for i, paper in enumerate(paper_list):
                    title = paper.find('p', class_='title is-5 mathjax').text.strip()
                    authors = paper.find('p', class_='authors').text.strip()
                    abstract = paper.find('span', class_='abstract-full').text.strip()
                    published_date = paper.find("p", class_="is-size-7").text.strip()

                    if i < quantity:
                        st.write(f'### {i+1}. {title}')
                        st.write(f'{"".join(authors.split())}')
                        st.write(f'æäº¤æ—¶é—´: {published_date}')
                        st.write(f'æ‘˜è¦: {abstract}')
                        abstract=translate_english_to_chinese(abstract)
                        st.write(f'ä¸­æ–‡ç¿»è¯‘: {abstract}')
                            
                            
                        st.write('---')

# åˆ›å»ºå¤šé¡µé¢åº”ç”¨ç¨‹åº
app_pages = {
    'GitHub': search_github,
    'Arxiv': search_arxiv
}

# æ˜¾ç¤ºé¡µé¢é€‰æ‹©å™¨
#page = st.sidebar.selectbox('é€‰æ‹©é¡µé¢', tuple(app_pages.keys()))
st.sidebar.write("æœç´¢ğŸ”¨")
st.sidebar.write("---")
page = st.sidebar.radio('é€‰æ‹©é¡µé¢', tuple(app_pages.keys()))

# æ‰§è¡Œé€‰æ‹©çš„é¡µé¢
app_pages[page]()
